{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-dzimchuk/ai-eng-projects/blob/main/project_1/lm_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe523821",
      "metadata": {
        "id": "fe523821"
      },
      "source": [
        "\n",
        "# Projectâ€¯1: Build an LLM Playground\n",
        "\n",
        "Welcome! In this project, youâ€™ll learn foundations of large language models (LLMs). Weâ€™ll keep the code minimal and the explanations highâ€‘level so that anyone who can run a Python cell can follow along.  \n",
        "\n",
        "We'll be using Google Colab for this project. Colab is a free, browser-based platform that lets you run Python code and machine learning models without installing anything on your local computer. Click the button below to open this notebook directly in Google Colab and get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb8584e",
      "metadata": {
        "id": "fdb8584e"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bytebyteai/ai-eng-projects/blob/main/project_1/lm_playground.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e82492",
      "metadata": {
        "id": "08e82492"
      },
      "source": [
        "---\n",
        "## Learning Objectives  \n",
        "* **Tokenization** and how raw text is tokenized into a sequene of discrete tokens\n",
        "* Inspect **GPT2** and **Transformer architecture**\n",
        "* Loading pre-trained LLMs using **Hugging Face**\n",
        "* **Decoding strategies** to generate text from LLMs\n",
        "* Completion versus **intrusction fine-tuned** LLMs\n",
        "\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1235110e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1235110e",
        "outputId": "f7cdbe57-a955-4920-908e-57b0dd60fbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.8.0+cu126 | transformers 4.57.0\n"
          ]
        }
      ],
      "source": [
        "import torch, transformers, tiktoken\n",
        "print(\"torch\", torch.__version__, \"| transformers\", transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c1eb0b",
      "metadata": {
        "id": "d4c1eb0b"
      },
      "source": [
        "# 1 - Tokenization\n",
        "\n",
        "A neural network canâ€™t digest raw text. They need **numbers**. Tokenization is the process of converting text into IDs. In this section, you'll learn how tokenization is implemented in practice.\n",
        "\n",
        "Tokenization methods generally fall into three categories:\n",
        "1. Word-level\n",
        "2. Character-level\n",
        "3. Subword-level"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d234dc0",
      "metadata": {
        "id": "1d234dc0"
      },
      "source": [
        "### 1.1 - Wordâ€‘level tokenization\n",
        "\n",
        "Split text on whitespace and store each **word** as a token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d784a288",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d784a288",
        "outputId": "e9276ea5-822a-4cf8-a7f5-984c80d5b78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 22 words\n",
            "First 15 vocab entries: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'Tokenization', 'converts', 'text', 'to', 'numbers', 'Large']\n",
            "\n",
            "Input text : The brown unicorn jumps\n",
            "Token IDs  : [0, 2, 21, 4]\n",
            "Decoded    : The brown [UNK] jumps\n"
          ]
        }
      ],
      "source": [
        "# 1. Tiny corpus\n",
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"Tokenization converts text to numbers\",\n",
        "    \"Large language models predict the next token\"\n",
        "]\n",
        "\n",
        "# 2. Build the vocabulary\n",
        "PAD, UNK = \"[PAD]\", \"[UNK]\"\n",
        "vocab = []\n",
        "word2id = {}\n",
        "id2word = {}\n",
        "\n",
        "for sentence in corpus:\n",
        "    for word in sentence.split():\n",
        "        if word not in word2id:\n",
        "            word2id[word] = len(vocab)\n",
        "            vocab.append(word)\n",
        "\n",
        "word2id[PAD] = len(vocab)\n",
        "vocab.append(PAD)\n",
        "word2id[UNK] = len(vocab)\n",
        "vocab.append(UNK)\n",
        "\n",
        "id2word = {id: word for word, id in word2id.items()}\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)} words\")\n",
        "print(\"First 15 vocab entries:\", vocab[:15])\n",
        "\n",
        "# 3. Encode / decode\n",
        "def encode(text):\n",
        "    ids = []\n",
        "    for word in text.split():\n",
        "        ids.append(word2id.get(word, word2id[UNK]))\n",
        "    return ids\n",
        "\n",
        "def decode(ids):\n",
        "    words = []\n",
        "    for id in ids:\n",
        "        words.append(id2word.get(id, UNK))\n",
        "    return \" \".join(words)\n",
        "\n",
        "# 4. Demo\n",
        "sample = \"The brown unicorn jumps\"\n",
        "ids = encode(sample)\n",
        "recovered = decode(ids)\n",
        "\n",
        "print(\"\\nInput text :\", sample)\n",
        "print(\"Token IDs  :\", ids)\n",
        "print(\"Decoded    :\", recovered)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0edab2c2",
      "metadata": {
        "id": "0edab2c2"
      },
      "source": [
        "Word-level tokenization has two major limitations:\n",
        "1. Large vocabulary size\n",
        "2. Out-of-vocabulary (OOV) issue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a379bac7",
      "metadata": {
        "id": "a379bac7"
      },
      "source": [
        "### 1.2 - Characterâ€‘level tokenization\n",
        "\n",
        "Every single character (including spaces and emojis) gets its own ID. This guarantees zero outâ€‘ofâ€‘vocabulary issues but very long sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ac29144",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ac29144",
        "outputId": "2313c9fd-3a74-4ed3-ea8c-b1f833e53ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 54 (52 letters + 2 specials)\n",
            "\n",
            "Input text : Hello\n",
            "Token IDs  : [33, 4, 11, 11, 14]\n",
            "Decoded    : Hello\n"
          ]
        }
      ],
      "source": [
        "# 1. Build a fixed vocabulary # aâ€“z + Aâ€“Z + padding + unknown\n",
        "import string\n",
        "\n",
        "vocab = []\n",
        "char2id = {}\n",
        "id2char = {}\n",
        "\n",
        "PAD, UNK = \"[PAD]\", \"[UNK]\"\n",
        "chars = list(string.ascii_letters) # a-z and A-Z\n",
        "vocab = chars + [PAD, UNK]\n",
        "char2id = {char: i for i, char in enumerate(vocab)}\n",
        "id2char = {i: char for char, i in char2id.items()}\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)} (52 letters + 2 specials)\")\n",
        "\n",
        "# 2. Encode / decode\n",
        "def encode(text):\n",
        "    ids = []\n",
        "    for char in text:\n",
        "        ids.append(char2id.get(char, char2id[UNK]))\n",
        "    return ids\n",
        "\n",
        "def decode(ids):\n",
        "    chars = []\n",
        "    for id in ids:\n",
        "        chars.append(id2char.get(id, UNK))\n",
        "    return \"\".join(chars)\n",
        "\n",
        "# 3. Demo\n",
        "sample = \"Hello\"\n",
        "ids = encode(sample)\n",
        "recovered = decode(ids)\n",
        "\n",
        "print(\"\\nInput text :\", sample)\n",
        "print(\"Token IDs  :\", ids)\n",
        "print(\"Decoded    :\", recovered)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391275bd",
      "metadata": {
        "id": "391275bd"
      },
      "source": [
        "### 1.3 - Subwordâ€‘level tokenization\n",
        "\n",
        "Sub-word methods such as `Byte-Pair Encoding (BPE)`, `WordPiece`, and `SentencePiece` **learn** the most common character and gorup them into new tokens. For example, the word `unbelievable` might turn into three tokens: `[\"un\", \"believ\", \"able\"]`. This approach strikes a balance between word-level and character-level methods and fix their limitations.\n",
        "\n",
        "For example, `BPE` algorithm forms the vocabulary using the following steps:\n",
        "1. **Start with bytes** â†’ every character is its own token.  \n",
        "2. **Count all adjacent pairs** in a huge corpus.  \n",
        "3. **Merge the most frequent pair** into a new token.  \n",
        "   *Repeat steps 2-3* until you hit the target vocab size (e.g., 50 k).\n",
        "\n",
        "Let's see `BPE` in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4675e67a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4675e67a",
        "outputId": "90a4cc6f-d321-4f50-f096-8e0750ffe126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input text : Unbelievable tokenization powers! ðŸš€\n",
            "Token IDs  : [3118, 6667, 11203, 540, 11241, 1634, 5635, 0, 12520, 248, 222]\n",
            "Tokens     : ['Un', 'bel', 'iev', 'able', 'Ä token', 'ization', 'Ä powers', '!', 'Ä Ã°Å', 'Ä¼', 'Ä¢']\n",
            "Decoded    : Unbelievable tokenization powers! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "# 1. Load a pretrained BPE tokenizer (GPT-2 uses BPE).\n",
        "# Refer to  https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "bpe_tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# 2. Encode / decode\n",
        "def encode(text):\n",
        "    return bpe_tok.encode(text)\n",
        "\n",
        "def decode(ids):\n",
        "    return bpe_tok.decode(ids)\n",
        "\n",
        "# 3. Demo\n",
        "sample = \"Unbelievable tokenization powers! ðŸš€\"\n",
        "ids = encode(sample)\n",
        "recovered = decode(ids)\n",
        "\n",
        "print(\"\\nInput text :\", sample)\n",
        "print(\"Token IDs  :\", ids)\n",
        "print(\"Tokens     :\", bpe_tok.convert_ids_to_tokens(ids))\n",
        "print(\"Decoded    :\", recovered)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "badaa5a8",
      "metadata": {
        "id": "badaa5a8"
      },
      "source": [
        "### 1.4 - TikToken\n",
        "\n",
        "`tiktoken` is a production-ready library which offers highâ€‘speed tokenization used by OpenAI models.  \n",
        "Let's compare the older **gpt2** encoding with the newer **cl100k_base** used in GPTâ€‘4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7704c470",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7704c470",
        "outputId": "db618a72-3698-46c1-c713-d7396b76259b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The ðŸŒŸ star-player scored 40 points!\n",
            "GPT-2 encoding: [464, 12520, 234, 253, 3491, 12, 7829, 7781, 2319, 2173, 0]\n",
            "GPT-2 decoding: The ðŸŒŸ star-player scored 40 points!\n",
            "CL100K_BASE encoding: [791, 11410, 234, 253, 6917, 43467, 16957, 220, 1272, 3585, 0]\n",
            "CL100K_BASE decoding: The ðŸŒŸ star-player scored 40 points!\n"
          ]
        }
      ],
      "source": [
        "# Use gpt2 and cl100k_base to encode and decode the following text\n",
        "# Refer to https://github.com/openai/tiktoken\n",
        "import tiktoken\n",
        "\n",
        "sentence = \"The ðŸŒŸ star-player scored 40 points!\"\n",
        "\n",
        "# Load encodings\n",
        "enc_gpt2 = tiktoken.get_encoding(\"gpt2\")\n",
        "enc_cl100k_base = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# Encode the sentence\n",
        "ids_gpt2 = enc_gpt2.encode(sentence)\n",
        "ids_cl100k_base = enc_cl100k_base.encode(sentence)\n",
        "\n",
        "# Decode the sentence\n",
        "recovered_gpt2 = enc_gpt2.decode(ids_gpt2)\n",
        "recovered_cl100k_base = enc_cl100k_base.decode(ids_cl100k_base)\n",
        "\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"GPT-2 encoding: {ids_gpt2}\")\n",
        "print(f\"GPT-2 decoding: {recovered_gpt2}\")\n",
        "print(f\"CL100K_BASE encoding: {ids_cl100k_base}\")\n",
        "print(f\"CL100K_BASE decoding: {recovered_cl100k_base}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8c1023",
      "metadata": {
        "id": "5e8c1023"
      },
      "source": [
        "Experiment: try new sentences, emojis, code snippets, or other languages. If you are interested, try implementing the BPE algorithm yourself.\n",
        "\n",
        "### 1.5 - Key Takeaways\n",
        "\n",
        "* **Wordâ€‘level**: simple but brittle (OOV problems).  \n",
        "* **Characterâ€‘level**: robust but produces long sequences.  \n",
        "* **BPE / Byteâ€‘Level BPE**: middle ground used by most LLMs.  \n",
        "* **tiktoken**: shows how production models tokenize with preâ€‘trained subâ€‘word vocabularies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a758ba",
      "metadata": {
        "id": "c2a758ba"
      },
      "source": [
        "# 2. What is a Language Model?\n",
        "\n",
        "At its core, a **language model (LM)** is just a *very large* mathematical function built from many neural-network layers.  \n",
        "Given a sequence of tokens `[tâ‚, tâ‚‚, â€¦, tâ‚™]`, it learns to output a probability for the next token `tâ‚™â‚Šâ‚`.\n",
        "\n",
        "\n",
        "Each layer applies a simple operation (matrix multiplication, attention, etc.). Stacking hundreds of these layers lets the model capture patterns and statistical relations from text. The final output is a vector of scores that says, â€œhow likely is each possible token to come next?â€\n",
        "\n",
        "> Think of the whole network as **one gigantic equation** whose parameters were tuned during training to minimize prediction error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0c7399",
      "metadata": {
        "id": "8f0c7399"
      },
      "source": [
        "\n",
        "### 2.1 - A Single `Linear` Layer\n",
        "\n",
        "Before we explore Transformer, letâ€™s start tiny:\n",
        "\n",
        "* A **Linear layer** performs `y = Wx + b`  \n",
        "  * `x` â€“ input vector  \n",
        "  * `W` â€“ weight matrix (learned)  \n",
        "  * `b` â€“ bias vector (learned)\n",
        "\n",
        "Although this looks basic, chaining thousands of such linear transforms (with nonlinearities in between) gives neural nets their expressive power.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e425948a",
      "metadata": {
        "id": "e425948a"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return F.linear(x, self.weight, self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13e5e225",
      "metadata": {
        "id": "13e5e225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac050c4-20e7-44a8-bf09-ce9fcad885be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : tensor([ 1.0000, -1.0000,  0.5000])\n",
            "Weights: Parameter containing:\n",
            "tensor([[-0.1771, -0.4588,  0.4916],\n",
            "        [ 0.0631,  0.1638, -0.4039]], requires_grad=True)\n",
            "Bias   : Parameter containing:\n",
            "tensor([-0.1131, -0.4047], requires_grad=True)\n",
            "Output : tensor([ 0.4145, -0.7073], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn, torch\n",
        "\n",
        "lin = nn.Linear(3, 2)\n",
        "x = torch.tensor([1.0, -1.0, 0.5])\n",
        "print(\"Input :\", x)\n",
        "print(\"Weights:\", lin.weight)\n",
        "print(\"Bias   :\", lin.bias)\n",
        "print(\"Output :\", lin(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a04f56bf",
      "metadata": {
        "id": "a04f56bf"
      },
      "source": [
        "### 2.2 - A `Transformer` Layer\n",
        "\n",
        "Most LLMs are a **stack of identical Transformer blocks**. Each block fuses two main components:\n",
        "\n",
        "| Step | What it does | Where it lives in code |\n",
        "|------|--------------|------------------------|\n",
        "| **Multi-Head Self-Attention** | Every token looks at every other token and decides *what matters*. | `block.attn` |\n",
        "| **Feed-Forward Network (MLP)** | Re-mixes information token-by-token. | `block.mlp` |\n",
        "\n",
        "Below, we load the smallest public GPT-2 (124 M parameters), grab its *first* block, and inspect the pieces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "47c87f6e",
      "metadata": {
        "id": "47c87f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29becda9-eb1b-40c9-e0fc-4cee1016e0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# Load the 124 M-parameter GPT-2 and inspect its layers (12 layers)\n",
        "gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "print(gpt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "92df06df",
      "metadata": {
        "id": "92df06df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64aa27a-cd65-46f8-9ec9-b121ce1f9a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output shape : torch.Size([1, 8, 768])\n"
          ]
        }
      ],
      "source": [
        "# Run a tiny forward pass through the first block\n",
        "seq_len = 8\n",
        "dummy_tokens = torch.randint(0, gpt2.config.vocab_size, (1, seq_len))\n",
        "with torch.no_grad():\n",
        "    # Embed tokens + positions the same way GPT-2 does\n",
        "    inputs_embeds = gpt2.transformer.wte(dummy_tokens) + gpt2.transformer.wpe(torch.arange(seq_len))\n",
        "    # Forward through one layer\n",
        "    out = gpt2.transformer.h[0](inputs_embeds)[0] # Access the tensor from the tuple\n",
        "\n",
        "print(\"\\nOutput shape :\", out.shape) # (batch, seq_len, hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8493ecc8",
      "metadata": {
        "id": "8493ecc8"
      },
      "source": [
        "### 2.3 - Inside GPT-2\n",
        "\n",
        "GPT-2 is just many of those modules arranged in a repeating *block*. Let's print the modules inside the Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a78ddee1",
      "metadata": {
        "id": "a78ddee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0256a1-97d4-4a14-b511-9ea8c9e5e0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: , Module: GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "Name: transformer, Module: GPT2Model(\n",
            "  (wte): Embedding(50257, 768)\n",
            "  (wpe): Embedding(1024, 768)\n",
            "  (drop): Dropout(p=0.1, inplace=False)\n",
            "  (h): ModuleList(\n",
            "    (0-11): 12 x GPT2Block(\n",
            "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): GPT2Attention(\n",
            "        (c_attn): Conv1D(nf=2304, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=768)\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): GPT2MLP(\n",
            "        (c_fc): Conv1D(nf=3072, nx=768)\n",
            "        (c_proj): Conv1D(nf=768, nx=3072)\n",
            "        (act): NewGELUActivation()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n",
            "Name: transformer.wte, Module: Embedding(50257, 768)\n",
            "Name: transformer.wpe, Module: Embedding(1024, 768)\n",
            "Name: transformer.drop, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h, Module: ModuleList(\n",
            "  (0-11): 12 x GPT2Block(\n",
            "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (attn): GPT2Attention(\n",
            "      (c_attn): Conv1D(nf=2304, nx=768)\n",
            "      (c_proj): Conv1D(nf=768, nx=768)\n",
            "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (mlp): GPT2MLP(\n",
            "      (c_fc): Conv1D(nf=3072, nx=768)\n",
            "      (c_proj): Conv1D(nf=768, nx=3072)\n",
            "      (act): NewGELUActivation()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.0, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.0.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.0.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.0.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.0.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.0.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.0.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.0.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.0.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.0.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.0.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.0.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.0.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.1, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.1.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.1.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.1.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.1.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.1.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.1.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.1.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.1.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.1.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.1.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.1.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.1.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.2, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.2.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.2.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.2.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.2.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.2.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.2.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.2.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.2.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.2.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.2.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.2.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.2.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.3, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.3.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.3.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.3.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.3.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.3.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.3.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.3.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.3.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.3.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.3.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.3.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.3.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.4, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.4.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.4.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.4.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.4.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.4.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.4.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.4.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.4.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.4.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.4.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.4.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.4.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.5, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.5.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.5.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.5.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.5.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.5.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.5.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.5.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.5.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.5.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.5.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.5.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.5.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.6, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.6.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.6.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.6.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.6.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.6.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.6.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.6.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.6.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.6.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.6.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.6.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.6.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.7, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.7.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.7.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.7.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.7.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.7.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.7.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.7.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.7.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.7.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.7.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.7.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.7.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.8, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.8.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.8.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.8.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.8.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.8.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.8.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.8.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.8.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.8.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.8.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.8.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.8.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.9, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.9.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.9.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.9.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.9.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.9.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.9.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.9.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.9.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.9.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.9.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.9.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.9.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.10, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.10.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.10.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.10.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.10.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.10.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.10.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.10.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.10.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.10.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.10.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.10.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.10.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.11, Module: GPT2Block(\n",
            "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (attn): GPT2Attention(\n",
            "    (c_attn): Conv1D(nf=2304, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=768)\n",
            "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (mlp): GPT2MLP(\n",
            "    (c_fc): Conv1D(nf=3072, nx=768)\n",
            "    (c_proj): Conv1D(nf=768, nx=3072)\n",
            "    (act): NewGELUActivation()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Name: transformer.h.11.ln_1, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.11.attn, Module: GPT2Attention(\n",
            "  (c_attn): Conv1D(nf=2304, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=768)\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.11.attn.c_attn, Module: Conv1D(nf=2304, nx=768)\n",
            "Name: transformer.h.11.attn.c_proj, Module: Conv1D(nf=768, nx=768)\n",
            "Name: transformer.h.11.attn.attn_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.11.attn.resid_dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.h.11.ln_2, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: transformer.h.11.mlp, Module: GPT2MLP(\n",
            "  (c_fc): Conv1D(nf=3072, nx=768)\n",
            "  (c_proj): Conv1D(nf=768, nx=3072)\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Name: transformer.h.11.mlp.c_fc, Module: Conv1D(nf=3072, nx=768)\n",
            "Name: transformer.h.11.mlp.c_proj, Module: Conv1D(nf=768, nx=3072)\n",
            "Name: transformer.h.11.mlp.act, Module: NewGELUActivation()\n",
            "Name: transformer.h.11.mlp.dropout, Module: Dropout(p=0.1, inplace=False)\n",
            "Name: transformer.ln_f, Module: LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Name: lm_head, Module: Linear(in_features=768, out_features=50257, bias=False)\n"
          ]
        }
      ],
      "source": [
        "# Print the name and modules inside gpt2\n",
        "for name, module in gpt2.named_modules():\n",
        "    print(f\"Name: {name}, Module: {module}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed029847",
      "metadata": {
        "id": "ed029847"
      },
      "source": [
        "As you can see, the Transformer holds various modules, arranged from a list of blocks (`h`). The following table summarizes these modules:\n",
        "\n",
        "| Step | What it does | Why it matters |\n",
        "|------|--------------|----------------|\n",
        "| **Token â†’ Embedding** | Converts IDs to vectors | Gives the model a numeric â€œhandleâ€ on words |\n",
        "| **Positional Encoding** | Adds â€œwhere am I?â€ info | Order matters in language |\n",
        "| **Multi-Head Self-Attention** | Each token asks â€œwhich other tokens should I look at?â€ | Lets the model relate words across a sentence |\n",
        "| **Feed-Forward Network** | Two stacked Linear layers with a non-linearity | Mixes information and adds depth |\n",
        "| **LayerNorm & Residual** | Stabilize training and help gradients flow | Keeps very deep networks trainable |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6a7495",
      "metadata": {
        "id": "0a6a7495"
      },
      "source": [
        "### 2.4 LLM's output\n",
        "\n",
        "Passing a token sequence through an **LLM** yields a tensor of **logits** with shape  \n",
        "`(batch_size, seq_len, vocab_size)`.  \n",
        "Applying `softmax` on the last dimension turns those logits into probabilities.\n",
        "\n",
        "The cell below feeds an 8-token dummy sequence, prints the logits shape, and shows the five most likely next tokens for the final position.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f98b7b34",
      "metadata": {
        "id": "f98b7b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287,
          "referenced_widgets": [
            "ebb81a555102493da9d0bbcfc5d4929d",
            "a2a5867710d147fa84a06f78d90e8efe",
            "7cbf25c98ee54aae918b5685a9eb9ecf",
            "e7bfd68f53f943b98eae5584007b18ee",
            "f1208b37569644348beb37e383063e8c",
            "4adaf77aea754e69b4136189a6386af8",
            "9b5ae770cfa146c8a2c01d498a502dcc",
            "9b1fc39f74d146cbaaaa51a1462894fb",
            "c73c191040d3410fa3c5eb00cfdd5b7e",
            "517b1da4a8e74bd09f0d4175acdff64a",
            "36b5da8c02964958b19df02d1d93eea6",
            "08ca0b85354149c08d069b43ac20a5af",
            "c6efc9a6a88e4213a9cbffd0552eddd1",
            "27aebde7aedf4a3a93e71707b085fb45",
            "6e35af0d064f4489bbd407be53105f30",
            "958562c4d3784443893923643de877ed",
            "d00cba22698847709f8223cadc0f0731",
            "0eaf9591c08440e78df20a7c9432aed0",
            "a397b65d19c84e3ebaac07aa782a95ff",
            "db1c9b4c887e41538078d0729c9654fc",
            "54898797a74947dd88a2d8b9bb0d3082",
            "2b0ebd281a094dbf9e97f34b87a8d707",
            "1056c0a7770046bbbba39c3489f28087",
            "f4db2a4e42f84cc5aeb56aaaa9216193",
            "8e5d05ad9ae5442c935026a54ef485cc",
            "91a50ba4029942309727a474a8c8a055",
            "c68c0c8a4f9244b88b62897bfb8b50d3",
            "0555962c7e7f4940ad1624af16ed9421",
            "8696e9e20ef7477097d0033671fe8436",
            "529da15ce2b247bd976b455aa26b5c6c",
            "4737ff51c4134a84839a8acf45cef0c4",
            "348368f4fb404fb5a63c773d87f3b8f1",
            "26aa962879c64a7e82462719874281ff",
            "b711b40ee0c9428289262a5d379776f7",
            "bb11353f957142eb8a331f65d8665da5",
            "95987efcd56e40699b5ba1316d3b1fc6",
            "d6eb0b785aed4812979b9a0366d34ede",
            "2706171659d947d480de26c9cb7904a4",
            "e5e5eec0dee541a89d5ac593e3c8c38a",
            "1363c61d3e754835ba2e8e50b79a9a6c",
            "f8b5db0fdcd84edda5cd33806cc8c811",
            "1117d2724b624a8bafabbebc8189f75e",
            "f165dc1ea6ad4da08ba6b6fbf1caa546",
            "73bb3efc0a6348d8b687818f5325eafb"
          ]
        },
        "outputId": "47927476-82be-4fc9-f4c2-9107178455eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebb81a555102493da9d0bbcfc5d4929d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08ca0b85354149c08d069b43ac20a5af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1056c0a7770046bbbba39c3489f28087"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b711b40ee0c9428289262a5d379776f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape : torch.Size([1, 3, 50257])\n",
            "\n",
            "Top-5 predictions for the next token:\n",
            "1:  is (0.7773)\n",
            "2: , (0.0373)\n",
            "3: 's (0.0332)\n",
            "4:  was (0.0127)\n",
            "5:  and (0.0076)\n"
          ]
        }
      ],
      "source": [
        "import torch, torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "# Load gpt2 model and tokenizer\n",
        "gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Tokenize input text\n",
        "text = \"Hello my name\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Get logits by passing the ids to the gpt2 model.\n",
        "with torch.no_grad():\n",
        "    outputs = gpt2(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "print(\"Logits shape :\", logits.shape)\n",
        "\n",
        "# Predict next token\n",
        "last_token_logits = logits[0, -1, :]\n",
        "probabilities = F.softmax(last_token_logits, dim=-1)\n",
        "top5_prob, top5_ids = torch.topk(probabilities, 5)\n",
        "\n",
        "print(\"\\nTop-5 predictions for the next token:\")\n",
        "for i in range(5):\n",
        "    token = tokenizer.decode([top5_ids[i]])\n",
        "    print(f\"{i+1}: {token} ({top5_prob[i]:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eb05c9b",
      "metadata": {
        "id": "0eb05c9b"
      },
      "source": [
        "### 2.5 - Key Takeaway\n",
        "\n",
        "A language model is nothing mystical: itâ€™s a *huge composition* of small, understandable layers trained to predict the next token in a sequence of tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ccf391",
      "metadata": {
        "id": "e0ccf391"
      },
      "source": [
        "# 3 - Generation\n",
        "Once an LLM is trained to predict the probabilities, we can generate text from the model. This process is called decoding or sampling.\n",
        "\n",
        "At each step, the LLM outputs a **probability distribution** over the next token. It is the job of the decoding algorithm to pick the next token, and move on to the next token. There are different decoding algorithms and hyper-parameters to control the generaiton:\n",
        "* **Greedy** â†’ pick the single highestâ€‘probability token each step (safe but repetitive).  \n",
        "* **Topâ€‘k / Nucleus (topâ€‘p)** â†’ sample from a subset of likely tokens (adds variety).\n",
        "* **beam** -> applies beam search to pick tokens\n",
        "* **Temperature** â†’ a *creativity* knob. Higher values flatten the probability distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac0c5728",
      "metadata": {
        "id": "ac0c5728"
      },
      "source": [
        "### 3.1 - Greedy decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2cb953",
      "metadata": {
        "id": "2f2cb953"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "MODELS = {\n",
        "    \"gpt2\": \"gpt2\",\n",
        "}\n",
        "tokenizers, models = {}, {}\n",
        "# Load models and tokenizers\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\"\n",
        "\n",
        "def generate(model_key, prompt, strategy=\"greedy\", max_new_tokens=100):\n",
        "    tok, mdl = tokenizers[model_key], models[model_key]\n",
        "    # Return the generations based on the provided strategy: greedy, top_k, top_p\n",
        "    \"\"\"\n",
        "    YOUR CODE HERE\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe777ba",
      "metadata": {
        "id": "dbe777ba"
      },
      "outputs": [],
      "source": [
        "tests=[\"Once upon a time\",\"What is 2+2?\", \"Suggest a party theme.\"]\n",
        "for prompt in tests:\n",
        "    print(f\"\\n== GPT-2 | Greedy ==\")\n",
        "    print(generate(\"gpt2\", prompt, \"greedy\", 80))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51d44b2",
      "metadata": {
        "id": "f51d44b2"
      },
      "source": [
        "\n",
        "Naively picking the single best token every time has the following issues in practice:\n",
        "\n",
        "* **Loop**: â€œThe cat is is isâ€¦â€  \n",
        "* **Miss long-term payoff**: the highest-probability word *now* might paint you into a boring corner later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91607661",
      "metadata": {
        "id": "91607661"
      },
      "source": [
        "### 3.2 - Top-k or top-p sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0633d4a3",
      "metadata": {
        "id": "0633d4a3"
      },
      "outputs": [],
      "source": [
        "\n",
        "tests=[\"Once upon a time\",\"What is 2+2?\", \"Suggest a party theme.\"]\n",
        "for prompt in tests:\n",
        "    print(f\"\\n== GPT-2 | Top-p ==\")\n",
        "    print(generate(\"gpt2\", prompt, \"top-p\", 40))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004b4039",
      "metadata": {
        "id": "004b4039"
      },
      "source": [
        "### 3.3 - Try It Yourself\n",
        "\n",
        "1. Scroll to the list called `tests`.\n",
        "2. Swap in your own prompts or tweak the decoding strategy.  \n",
        "3. Reâ€‘run the cell and compare the vibes.\n",
        "\n",
        "> **Tip:** Try the same prompt with `greedy` vs. `top_p` (0.9) and see how the tone changes. Notice especially how small temperature tweaks can soften or sharpen the prose.\n",
        "\n",
        "* `strategy`: `\"greedy\"`, `\"beam\"`, `\"top_k\"`, `\"top_p\"`  \n",
        "* `temperature`: `0.2 â€“ 2.0`  \n",
        "* `k` or `p` thresholds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b775b02",
      "metadata": {
        "id": "6b775b02"
      },
      "source": [
        "# 4 - Completion vs. Instruction-tuned LLMs\n",
        "\n",
        "We have seen that we can use GPT2 model to pass an input text and generate a new text. However, this model only continues the provided text. It is not engaging in a dialouge-like conversation and cannot be helpful by answering instructions. On the other hand, **instruction-tuned LLMs** like `Qwen-Chat` go through an extra training stage called **post-training** after the base â€œcompletionâ€ model is finished. Because of post-training step, an instruction-tuned LLM will:\n",
        "\n",
        "* **Read the entire prompt as a request,** not just as text to mimic.  \n",
        "* **Stay in dialogue mode**. Answer questions, follow steps, ask clarifying queries.  \n",
        "* **Refuse or safe-complete** when instructions are unsafe or disallowed.  \n",
        "* **Adopt a consistent persona** (e.g., â€œAssistantâ€) rather than drifting into story continuation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1706dc08",
      "metadata": {
        "id": "1706dc08"
      },
      "source": [
        "### 4.1 - Qwen1.5-8B vs. GPT2\n",
        "\n",
        "In the code below weâ€™ll feed the same prompt to:\n",
        "\n",
        "* **GPT-2 (completion-only)** â€“ it will simply keep writing in the same style.  \n",
        "* **Qwen-Chat (instruction-tuned)** â€“ it will obey the instruction and respond directly.\n",
        "\n",
        "Comparing the two outputs makes the difference easy to see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b73e7a",
      "metadata": {
        "id": "57b73e7a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "MODELS = {\n",
        "    \"gpt2\": \"gpt2\",\n",
        "    \"qwen\": \"Qwen/Qwen1.5-1.8B-Chat\"\n",
        "}\n",
        "tokenizers, models = {}, {}\n",
        "# Load models and tokenizers\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef49ab1b",
      "metadata": {
        "id": "ef49ab1b"
      },
      "source": [
        "\n",
        "We downloaded two tiny checkpoints: `GPTâ€‘2` (124â€¯M parameters) and `Qwenâ€‘1.5â€‘Chat` (1.8â€¯B). If the cell took a while, that was mostly network time. Models are stored locally after the first run.\n",
        "\n",
        "Let's now generate text and compare two models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c78a508",
      "metadata": {
        "id": "0c78a508"
      },
      "outputs": [],
      "source": [
        "\n",
        "tests=[(\"Once upon a time\",\"greedy\"),(\"What is 2+2?\",\"top_k\"),(\"Suggest a party theme.\",\"top_p\")]\n",
        "for prompt,strategy in tests:\n",
        "    for key in [\"gpt2\",\"qwen\"]:\n",
        "        print(f\"\\n== {key.upper()} | {strategy} ==\")\n",
        "        print(generate(key,prompt,strategy,80))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e1c3da1",
      "metadata": {
        "id": "8e1c3da1"
      },
      "source": [
        "# 5. (Optional) A Small LLM Playground"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313ba974",
      "metadata": {
        "id": "313ba974"
      },
      "source": [
        "### 5.1â€¯â€‘ Interactive Playground\n",
        "\n",
        "Enter a prompt, pick a model and decoding strategy, adjust the temperature, and press **Generate** to watch the model respond.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a67a884",
      "metadata": {
        "id": "1a67a884"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Make sure models and tokenizers are loaded\n",
        "try:\n",
        "    tokenizers\n",
        "    models\n",
        "except NameError:\n",
        "    raise RuntimeError(\"Please run the earlier setup cells that load the models before using the playground.\")\n",
        "\n",
        "def generate_playground(model_key, prompt, strategy=\"greedy\", temperature=1.0, max_new_tokens=100):\n",
        "    # Generation code\n",
        "    \"\"\"\n",
        "    YOUR CODE HERE\n",
        "    \"\"\"\n",
        "\n",
        "# Your code to build boxes, dropdowns, and other elements in the UI using widgets and creating the UI using widgets.vbox and display.\n",
        "# Refer to https://ipywidgets.readthedocs.io/en/stable/\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfbccead",
      "metadata": {
        "id": "cfbccead"
      },
      "source": [
        "\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "Youâ€™ve just learned, explored, and inspected a real **LLM**. In one project you:\n",
        "* Learned how **tokenization** works in practice\n",
        "* Used `tiktoken` library to load and experiment with most advanced tokenizers.\n",
        "* Explored LLM architecture and inspected GPT2 blocks and layers\n",
        "* Learned decoding strategies and used `top-p` to generate text from GPT2\n",
        "* Loaded a powerful chat model, `Qwen1.5-8B` and generated text\n",
        "* Built an LLM playground\n",
        "\n",
        "\n",
        "ðŸ‘ **Great job!** Take a moment to celebrate. You now have a working mental model of how LLMs work. The skills you used here power most LLMs you see everywhere.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30824bd6",
      "metadata": {
        "id": "30824bd6"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "llm_playground",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ebb81a555102493da9d0bbcfc5d4929d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2a5867710d147fa84a06f78d90e8efe",
              "IPY_MODEL_7cbf25c98ee54aae918b5685a9eb9ecf",
              "IPY_MODEL_e7bfd68f53f943b98eae5584007b18ee"
            ],
            "layout": "IPY_MODEL_f1208b37569644348beb37e383063e8c"
          }
        },
        "a2a5867710d147fa84a06f78d90e8efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4adaf77aea754e69b4136189a6386af8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9b5ae770cfa146c8a2c01d498a502dcc",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "7cbf25c98ee54aae918b5685a9eb9ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1fc39f74d146cbaaaa51a1462894fb",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c73c191040d3410fa3c5eb00cfdd5b7e",
            "value": 26
          }
        },
        "e7bfd68f53f943b98eae5584007b18ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517b1da4a8e74bd09f0d4175acdff64a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_36b5da8c02964958b19df02d1d93eea6",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡1.74kB/s]"
          }
        },
        "f1208b37569644348beb37e383063e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4adaf77aea754e69b4136189a6386af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5ae770cfa146c8a2c01d498a502dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b1fc39f74d146cbaaaa51a1462894fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73c191040d3410fa3c5eb00cfdd5b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "517b1da4a8e74bd09f0d4175acdff64a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b5da8c02964958b19df02d1d93eea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ca0b85354149c08d069b43ac20a5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6efc9a6a88e4213a9cbffd0552eddd1",
              "IPY_MODEL_27aebde7aedf4a3a93e71707b085fb45",
              "IPY_MODEL_6e35af0d064f4489bbd407be53105f30"
            ],
            "layout": "IPY_MODEL_958562c4d3784443893923643de877ed"
          }
        },
        "c6efc9a6a88e4213a9cbffd0552eddd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00cba22698847709f8223cadc0f0731",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0eaf9591c08440e78df20a7c9432aed0",
            "value": "vocab.json:â€‡100%"
          }
        },
        "27aebde7aedf4a3a93e71707b085fb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a397b65d19c84e3ebaac07aa782a95ff",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db1c9b4c887e41538078d0729c9654fc",
            "value": 1042301
          }
        },
        "6e35af0d064f4489bbd407be53105f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54898797a74947dd88a2d8b9bb0d3082",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2b0ebd281a094dbf9e97f34b87a8d707",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡4.70MB/s]"
          }
        },
        "958562c4d3784443893923643de877ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00cba22698847709f8223cadc0f0731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eaf9591c08440e78df20a7c9432aed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a397b65d19c84e3ebaac07aa782a95ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1c9b4c887e41538078d0729c9654fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54898797a74947dd88a2d8b9bb0d3082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0ebd281a094dbf9e97f34b87a8d707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1056c0a7770046bbbba39c3489f28087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4db2a4e42f84cc5aeb56aaaa9216193",
              "IPY_MODEL_8e5d05ad9ae5442c935026a54ef485cc",
              "IPY_MODEL_91a50ba4029942309727a474a8c8a055"
            ],
            "layout": "IPY_MODEL_c68c0c8a4f9244b88b62897bfb8b50d3"
          }
        },
        "f4db2a4e42f84cc5aeb56aaaa9216193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0555962c7e7f4940ad1624af16ed9421",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8696e9e20ef7477097d0033671fe8436",
            "value": "merges.txt:â€‡100%"
          }
        },
        "8e5d05ad9ae5442c935026a54ef485cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529da15ce2b247bd976b455aa26b5c6c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4737ff51c4134a84839a8acf45cef0c4",
            "value": 456318
          }
        },
        "91a50ba4029942309727a474a8c8a055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348368f4fb404fb5a63c773d87f3b8f1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_26aa962879c64a7e82462719874281ff",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡6.19MB/s]"
          }
        },
        "c68c0c8a4f9244b88b62897bfb8b50d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0555962c7e7f4940ad1624af16ed9421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8696e9e20ef7477097d0033671fe8436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "529da15ce2b247bd976b455aa26b5c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4737ff51c4134a84839a8acf45cef0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "348368f4fb404fb5a63c773d87f3b8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26aa962879c64a7e82462719874281ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b711b40ee0c9428289262a5d379776f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb11353f957142eb8a331f65d8665da5",
              "IPY_MODEL_95987efcd56e40699b5ba1316d3b1fc6",
              "IPY_MODEL_d6eb0b785aed4812979b9a0366d34ede"
            ],
            "layout": "IPY_MODEL_2706171659d947d480de26c9cb7904a4"
          }
        },
        "bb11353f957142eb8a331f65d8665da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e5eec0dee541a89d5ac593e3c8c38a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1363c61d3e754835ba2e8e50b79a9a6c",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "95987efcd56e40699b5ba1316d3b1fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b5db0fdcd84edda5cd33806cc8c811",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1117d2724b624a8bafabbebc8189f75e",
            "value": 1355256
          }
        },
        "d6eb0b785aed4812979b9a0366d34ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f165dc1ea6ad4da08ba6b6fbf1caa546",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_73bb3efc0a6348d8b687818f5325eafb",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡9.19MB/s]"
          }
        },
        "2706171659d947d480de26c9cb7904a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e5eec0dee541a89d5ac593e3c8c38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1363c61d3e754835ba2e8e50b79a9a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b5db0fdcd84edda5cd33806cc8c811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1117d2724b624a8bafabbebc8189f75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f165dc1ea6ad4da08ba6b6fbf1caa546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bb3efc0a6348d8b687818f5325eafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}